# Application Environment
APP_ENV=development
LOG_LEVEL=INFO

# Database Configuration
DATABASE_URL=postgresql://postgres:postgres@db:5432/medical_db
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30

# Redis Configuration
REDIS_URL=redis://redis:6379/0

# LLM Provider Configuration
# Options: ollama, openai, anthropic
LLM_PROVIDER=ollama

# Ollama Settings (default - free, local)
# For bundled Ollama: http://ollama:11434
# For external Ollama: http://host.docker.internal:11434 (Mac/Windows)
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=llama3.2

# Ollama Performance Tuning (see PROVIDERS.md for details)
OLLAMA_TEMPERATURE=0.3
OLLAMA_TOP_P=0.9
OLLAMA_TOP_K=40
OLLAMA_NUM_CTX=4096
# OLLAMA_NUM_PREDICT=  # Leave empty for auto (based on max_length)
OLLAMA_TIMEOUT=60

# OpenAI Settings (requires API key)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-3.5-turbo

# Anthropic Settings (requires API key)
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Security
SECRET_KEY=change-this-in-production
CORS_ORIGINS=*

# Monitoring
METRICS_ENABLED=true
